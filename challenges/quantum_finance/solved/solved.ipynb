{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and clean time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "from utils import fetch_log_returns\n",
    "training_dataset = fetch_log_returns(start = '1995-01-01', end ='1995-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp500</th>\n",
       "      <th>dax</th>\n",
       "      <th>ftse</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ibex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-01-05 00:00:00+00:00</th>\n",
       "      <td>-0.000803</td>\n",
       "      <td>-0.010397</td>\n",
       "      <td>-0.006345</td>\n",
       "      <td>-0.003457</td>\n",
       "      <td>-0.019565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-06 00:00:00+00:00</th>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>-0.004939</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-09 00:00:00+00:00</th>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.003826</td>\n",
       "      <td>-0.014346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-10 00:00:00+00:00</th>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>-0.005274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-11 00:00:00+00:00</th>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.003601</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>-0.010125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sp500       dax      ftse    nikkei      ibex\n",
       "Date                                                                       \n",
       "1995-01-05 00:00:00+00:00 -0.000803 -0.010397 -0.006345 -0.003457 -0.019565\n",
       "1995-01-06 00:00:00+00:00  0.000738  0.003280  0.010726 -0.004939  0.000000\n",
       "1995-01-09 00:00:00+00:00  0.000326 -0.002330 -0.003006 -0.003826 -0.014346\n",
       "1995-01-10 00:00:00+00:00  0.001843  0.004213  0.001504  0.002903 -0.005274\n",
       "1995-01-11 00:00:00+00:00 -0.000043 -0.000155 -0.003601  0.002408 -0.010125"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the problem instance and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_params import LAMBDA_1, LAMBDA_2, LAMBDA_3, NLAYERS, NSHOTS, NUM_ASSETS, SIGMA_TARGET, TWO_QUBIT_GATES, K, N, RISK_FREE_RATE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the circuit Ansatz (without angle embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware efficient circuit ansatz\n",
      "\n",
      "q0: ─U2─U2─o───────U1─U2─o───────U1─M─\n",
      "q1: ─U2─U2─X─o─────U1─U2─X─o─────U1─M─\n",
      "q2: ─U2─U2───X─o───U1─U2───X─o───U1─M─\n",
      "q3: ─U2─U2─────X─o─U1─U2─────X─o─U1─M─\n",
      "q4: ─U2─U2───────X─U1─U2───────X─U1─M─\n"
     ]
    }
   ],
   "source": [
    "from ansatz import build_hardware_efficient_ansatz\n",
    "from ansatz import compute_number_of_params\n",
    "ansatz = build_hardware_efficient_ansatz(num_qubits=N, num_layers=NLAYERS, params=[0]*compute_number_of_params(N,NLAYERS))\n",
    "print('Hardware efficient circuit ansatz')\n",
    "print()\n",
    "print(ansatz.draw())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Portfolio Optimization Hamiltonian and run the optimization process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Qibo 0.2.8|INFO|2024-10-03 20:24:43]: Using numpy backend on /CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground state energy: 156.30049210320266\n",
      "\n",
      "Optimal parameters [3.28747628 5.394333   1.78260901 1.96569609 4.92335797 4.83797578\n",
      " 4.5243877  4.78963462 2.09453765 4.65253642 1.65320103 1.11342001\n",
      " 2.80865349 2.48452671 3.28107242 3.87547935 0.90789148 3.99348565\n",
      " 3.17187684 4.44027871 1.17560957 2.0704244  5.35520415 2.51829988\n",
      " 4.76580599 4.57446476 4.42964952 0.05158818 2.69127382 2.22238238\n",
      " 3.75670278 4.79705541 0.99956735 5.96246604 3.21909487 5.63548272\n",
      " 0.33550344 5.88756038 0.92545495 6.2039591 ]\n",
      "\n",
      "Optimization process info  message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 156.30049210320266\n",
      "       x: [ 3.287e+00  5.394e+00 ...  9.255e-01  6.204e+00]\n",
      "     nit: 1\n",
      "   direc: [[ 1.000e+00  0.000e+00 ...  0.000e+00  0.000e+00]\n",
      "           [ 0.000e+00  1.000e+00 ...  0.000e+00  0.000e+00]\n",
      "           ...\n",
      "           [ 0.000e+00  0.000e+00 ...  1.000e+00  0.000e+00]\n",
      "           [ 0.000e+00  0.000e+00 ...  0.000e+00  1.000e+00]]\n",
      "    nfev: 121\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qibo.optimizers import optimize\n",
    "from cost_function import compute_total_energy\n",
    "\n",
    "# Optimize starting from a random guess for the variational parameters\n",
    "initial_params = np.random.uniform(0, 2*np.pi, compute_number_of_params(N,NLAYERS))\n",
    "\n",
    "# perform optimization\n",
    "best, optimal_params, extra = optimize(compute_total_energy, initial_params, args=(training_dataset))\n",
    "\n",
    "# set final solution to circuit instance\n",
    "print('Ground state energy:', best)\n",
    "print()\n",
    "print('Optimal parameters', optimal_params)\n",
    "print()\n",
    "print('Optimization process info', extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0625"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_minimum_energy(portfolios: pd.DataFrame) -> float:\n",
    "    energies = []\n",
    "    for data in portfolios.values():\n",
    "        energies.append(data['energy'])\n",
    "    return min(energies)\n",
    "get_minimum_energy(optimal_binary_portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import number\n",
    "from qibo.result import CircuitResult\n",
    "def get_max_prob(result: CircuitResult, nshots: int = NSHOTS) -> float:\n",
    "    number_of_times = result.frequencies().values()\n",
    "    probs = [freq/nshots for freq in number_of_times]\n",
    "    return max(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ansatz(nshots=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qibo.models import Circuit\n",
    "from cost_function import compute_cost_function\n",
    "from utils import string_to_int_list\n",
    "import pandas as pd\n",
    "TOLERANCE = 0.5\n",
    "\n",
    "def get_optimal_binary_portfolios(ansatz: Circuit, dataset: pd.DataFrame, nshots: int = NSHOTS, tolerance: int = TOLERANCE) -> dict:\n",
    "    result = ansatz(nshots=nshots)\n",
    "    optimal_portfolios = {}\n",
    "    for bit_string, stat_freq in result.frequencies().items():\n",
    "        if (get_max_prob(result) - stat_freq/nshots) < tolerance:\n",
    "            optimal_portfolios[bit_string] = {'stat_freq': stat_freq/nshots, 'energy': compute_cost_function(dataset, string_to_int_list(bit_string))}\n",
    "    return optimal_portfolios\n",
    "\n",
    "\n",
    "optimized_ansatz = ansatz.set_parameters(optimal_params)\n",
    "optimal_binary_portfolios = get_optimal_binary_portfolios(ansatz, training_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00000': {'stat_freq': 0.04, 'energy': 264.033506669926},\n",
       " '00001': {'stat_freq': 0.01, 'energy': 224.9904736273165},\n",
       " '00010': {'stat_freq': 0.03, 'energy': 224.97217237979967},\n",
       " '00101': {'stat_freq': 0.02, 'energy': 189.0766958797133},\n",
       " '00111': {'stat_freq': 0.01, 'energy': 156.26536158961062},\n",
       " '01000': {'stat_freq': 0.11, 'energy': 224.98184885674965},\n",
       " '01001': {'stat_freq': 0.02, 'energy': 189.0638158141494},\n",
       " '01010': {'stat_freq': 0.06, 'energy': 189.04551456665496},\n",
       " '01100': {'stat_freq': 0.04, 'energy': 189.06807110915688},\n",
       " '01110': {'stat_freq': 0.03, 'energy': 156.2567368190767},\n",
       " '10000': {'stat_freq': 0.04, 'energy': 225.0073028934075},\n",
       " '10001': {'stat_freq': 0.05, 'energy': 189.08926985080106},\n",
       " '10010': {'stat_freq': 0.06, 'energy': 189.07096860329156},\n",
       " '10011': {'stat_freq': 0.01, 'energy': 156.27793556069423},\n",
       " '10100': {'stat_freq': 0.06, 'energy': 189.09352514580488},\n",
       " '10101': {'stat_freq': 0.04, 'energy': 156.30049210320266},\n",
       " '10110': {'stat_freq': 0.04, 'energy': 156.28219085570345},\n",
       " '11000': {'stat_freq': 0.04, 'energy': 189.08064508024165},\n",
       " '11001': {'stat_freq': 0.06, 'energy': 156.28761203764444},\n",
       " '11010': {'stat_freq': 0.06, 'energy': 156.26931079015733},\n",
       " '11011': {'stat_freq': 0.02, 'energy': 126.60127774756921},\n",
       " '11100': {'stat_freq': 0.04, 'energy': 156.2918673326537},\n",
       " '11101': {'stat_freq': 0.03, 'energy': 126.62383429006069},\n",
       " '11110': {'stat_freq': 0.07, 'energy': 126.6055330425839},\n",
       " '11111': {'stat_freq': 0.01, 'energy': 100.0625}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_binary_portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sp500': '0', 'dax': '0', 'ftse': '0', 'nikkei': '0', 'ibex': '0'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_asset_weights_binary(assets, ordered_bitstring, num_qubit_per_asset = K):\n",
    "    weights = [ordered_bitstring[i:i+num_qubit_per_asset] for i in range(0, len(ordered_bitstring),num_qubit_per_asset)]\n",
    "    return dict(zip(assets,weights))\n",
    "\n",
    "optimal_binary_portfolio=list(optimal_binary_portfolios.keys())[0]\n",
    "\n",
    "binary_asset_weights = get_asset_weights_binary(training_dataset.columns, optimal_binary_portfolio)\n",
    "binary_asset_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_asset_weight_decimal(asset_bit_string):\n",
    "    w = 0\n",
    "    for k,bit in enumerate(asset_bit_string):\n",
    "       w += 2**(k-1)*int(bit)*1/(2**len(asset_bit_string)) # discretization !\n",
    "    return w  \n",
    "\n",
    "get_asset_weight_decimal(binary_asset_weights['nikkei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sp500': 0.0, 'dax': 0.0, 'ftse': 0.0, 'nikkei': 0.0, 'ibex': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio = {}\n",
    "for asset, w in binary_asset_weights.items():\n",
    "    portfolio[asset] = get_asset_weight_decimal(w)\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating portfolio metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1297365/2935572182.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_weights = list(portfolio.values()) / np.sum(list(portfolio.values()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Returns': 0.0,\n",
       " 'Volatility': nan,\n",
       " 'Sharpe Ratio': nan,\n",
       " 'Normalized Weights': array([nan, nan, nan, nan, nan])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_portfolio_metrics(portfolio: dict, dataset: pd.DataFrame, r: float = RISK_FREE_RATE):\n",
    "    import numpy as np\n",
    "    normalized_weights = list(portfolio.values()) / np.sum(list(portfolio.values()))\n",
    "\n",
    "\n",
    "    # Calculate the expected log returns, and add them to the `returns_array`.\n",
    "    annualized_ret_portfolio = np.sum((dataset.mean() * normalized_weights) * 252)\n",
    "\n",
    "\n",
    "    # Calculate the volatility, and add them to the `volatility_array`.\n",
    "    annualized_vol_portfolio = np.sqrt(\n",
    "        np.dot(normalized_weights.T, np.dot(dataset.cov() * 252, normalized_weights))\n",
    "    )\n",
    "    annualized_ret_portfolio,annualized_vol_portfolio\n",
    "\n",
    "    # Calculate the Sharpe Ratio and Add it to the `sharpe_ratio_array`.\n",
    "    sharpe_ratio= (annualized_ret_portfolio-r)/annualized_vol_portfolio\n",
    "\n",
    "    # Let's create our \"Master Data Frame\", with the weights, the returns, the volatility, and the Sharpe Ratio\n",
    "    return {'Returns':annualized_ret_portfolio, 'Volatility':annualized_vol_portfolio, 'Sharpe Ratio':sharpe_ratio, 'Normalized Weights':normalized_weights}\n",
    "get_portfolio_metrics(portfolio, training_dataset, r=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haqtoberfest24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
